{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdafa992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root_path = os.path.abspath(\"..\")  \n",
    "if root_path not in sys.path:\n",
    "    sys.path.insert(0, root_path)\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5426f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>accelerometer_x</th>\n",
       "      <th>accelerometer_y</th>\n",
       "      <th>accelerometer_z</th>\n",
       "      <th>gyroscope_x</th>\n",
       "      <th>gyroscope_y</th>\n",
       "      <th>gyroscope_z</th>\n",
       "      <th>magnetometer_x</th>\n",
       "      <th>magnetometer_y</th>\n",
       "      <th>magnetometer_z</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>actitivy_label</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>magnetometer_module</th>\n",
       "      <th>gyroscope_module</th>\n",
       "      <th>accelerometer_module</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.82430</td>\n",
       "      <td>9.1773</td>\n",
       "      <td>2.2388</td>\n",
       "      <td>-1.43340</td>\n",
       "      <td>-0.003309</td>\n",
       "      <td>-0.41384</td>\n",
       "      <td>-0.85484</td>\n",
       "      <td>0.50402</td>\n",
       "      <td>0.674830</td>\n",
       "      <td>1735.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.200076</td>\n",
       "      <td>1.491948</td>\n",
       "      <td>9.859601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.80020</td>\n",
       "      <td>9.1655</td>\n",
       "      <td>2.2507</td>\n",
       "      <td>-1.04340</td>\n",
       "      <td>0.230960</td>\n",
       "      <td>-0.12186</td>\n",
       "      <td>-0.85887</td>\n",
       "      <td>0.52610</td>\n",
       "      <td>0.674830</td>\n",
       "      <td>1754.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.212367</td>\n",
       "      <td>1.075582</td>\n",
       "      <td>9.844448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.78810</td>\n",
       "      <td>9.1296</td>\n",
       "      <td>2.2634</td>\n",
       "      <td>-1.12080</td>\n",
       "      <td>0.215210</td>\n",
       "      <td>-0.10277</td>\n",
       "      <td>-0.85081</td>\n",
       "      <td>0.52811</td>\n",
       "      <td>0.683740</td>\n",
       "      <td>1774.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.212550</td>\n",
       "      <td>1.145893</td>\n",
       "      <td>9.810509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.82400</td>\n",
       "      <td>9.1173</td>\n",
       "      <td>2.2522</td>\n",
       "      <td>-1.15170</td>\n",
       "      <td>0.143390</td>\n",
       "      <td>0.32778</td>\n",
       "      <td>-0.84879</td>\n",
       "      <td>0.50402</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>1793.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.203370</td>\n",
       "      <td>1.205991</td>\n",
       "      <td>9.806760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.82400</td>\n",
       "      <td>9.1414</td>\n",
       "      <td>2.2517</td>\n",
       "      <td>-1.36180</td>\n",
       "      <td>-0.113230</td>\n",
       "      <td>0.65311</td>\n",
       "      <td>-0.86290</td>\n",
       "      <td>0.51807</td>\n",
       "      <td>0.683740</td>\n",
       "      <td>1813.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.216755</td>\n",
       "      <td>1.514554</td>\n",
       "      <td>9.829055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53114</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.48220</td>\n",
       "      <td>9.4431</td>\n",
       "      <td>-2.1914</td>\n",
       "      <td>0.70696</td>\n",
       "      <td>-0.734460</td>\n",
       "      <td>1.05760</td>\n",
       "      <td>-0.13535</td>\n",
       "      <td>0.71257</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>1038000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728639</td>\n",
       "      <td>1.468925</td>\n",
       "      <td>9.706023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53115</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.47013</td>\n",
       "      <td>9.4553</td>\n",
       "      <td>-2.1919</td>\n",
       "      <td>0.23155</td>\n",
       "      <td>-0.340820</td>\n",
       "      <td>0.98911</td>\n",
       "      <td>-0.12525</td>\n",
       "      <td>0.67265</td>\n",
       "      <td>0.071739</td>\n",
       "      <td>1038000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687962</td>\n",
       "      <td>1.071500</td>\n",
       "      <td>9.717415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53116</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.49463</td>\n",
       "      <td>9.4428</td>\n",
       "      <td>-2.2155</td>\n",
       "      <td>0.53524</td>\n",
       "      <td>-0.291600</td>\n",
       "      <td>1.00350</td>\n",
       "      <td>-0.11919</td>\n",
       "      <td>0.69461</td>\n",
       "      <td>0.071739</td>\n",
       "      <td>1038000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708404</td>\n",
       "      <td>1.174106</td>\n",
       "      <td>9.711826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53117</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.47013</td>\n",
       "      <td>9.4553</td>\n",
       "      <td>-2.1919</td>\n",
       "      <td>0.23140</td>\n",
       "      <td>-0.326390</td>\n",
       "      <td>0.89815</td>\n",
       "      <td>-0.11313</td>\n",
       "      <td>0.72056</td>\n",
       "      <td>0.084783</td>\n",
       "      <td>1038100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734298</td>\n",
       "      <td>0.983234</td>\n",
       "      <td>9.717415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53118</th>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.49427</td>\n",
       "      <td>9.4431</td>\n",
       "      <td>-2.1790</td>\n",
       "      <td>0.36537</td>\n",
       "      <td>-0.035469</td>\n",
       "      <td>0.69252</td>\n",
       "      <td>-0.12929</td>\n",
       "      <td>0.72455</td>\n",
       "      <td>0.078261</td>\n",
       "      <td>1038100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740144</td>\n",
       "      <td>0.783797</td>\n",
       "      <td>9.703838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3930798 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       device_id  accelerometer_x  accelerometer_y  accelerometer_z  \\\n",
       "0            1.0         -2.82430           9.1773           2.2388   \n",
       "1            1.0         -2.80020           9.1655           2.2507   \n",
       "2            1.0         -2.78810           9.1296           2.2634   \n",
       "3            1.0         -2.82400           9.1173           2.2522   \n",
       "4            1.0         -2.82400           9.1414           2.2517   \n",
       "...          ...              ...              ...              ...   \n",
       "53114        5.0         -0.48220           9.4431          -2.1914   \n",
       "53115        5.0         -0.47013           9.4553          -2.1919   \n",
       "53116        5.0         -0.49463           9.4428          -2.2155   \n",
       "53117        5.0         -0.47013           9.4553          -2.1919   \n",
       "53118        5.0         -0.49427           9.4431          -2.1790   \n",
       "\n",
       "       gyroscope_x  gyroscope_y  gyroscope_z  magnetometer_x  magnetometer_y  \\\n",
       "0         -1.43340    -0.003309     -0.41384        -0.85484         0.50402   \n",
       "1         -1.04340     0.230960     -0.12186        -0.85887         0.52610   \n",
       "2         -1.12080     0.215210     -0.10277        -0.85081         0.52811   \n",
       "3         -1.15170     0.143390      0.32778        -0.84879         0.50402   \n",
       "4         -1.36180    -0.113230      0.65311        -0.86290         0.51807   \n",
       "...            ...          ...          ...             ...             ...   \n",
       "53114      0.70696    -0.734460      1.05760        -0.13535         0.71257   \n",
       "53115      0.23155    -0.340820      0.98911        -0.12525         0.67265   \n",
       "53116      0.53524    -0.291600      1.00350        -0.11919         0.69461   \n",
       "53117      0.23140    -0.326390      0.89815        -0.11313         0.72056   \n",
       "53118      0.36537    -0.035469      0.69252        -0.12929         0.72455   \n",
       "\n",
       "       magnetometer_z  timestamp  actitivy_label  participant_id  \\\n",
       "0            0.674830     1735.1             1.0              14   \n",
       "1            0.674830     1754.6             1.0              14   \n",
       "2            0.683740     1774.2             1.0              14   \n",
       "3            0.688200     1793.7             1.0              14   \n",
       "4            0.683740     1813.2             1.0              14   \n",
       "...               ...        ...             ...             ...   \n",
       "53114        0.069565  1038000.0             1.0               0   \n",
       "53115        0.071739  1038000.0             1.0               0   \n",
       "53116        0.071739  1038000.0             1.0               0   \n",
       "53117        0.084783  1038100.0             1.0               0   \n",
       "53118        0.078261  1038100.0             1.0               0   \n",
       "\n",
       "       magnetometer_module  gyroscope_module  accelerometer_module  \n",
       "0                 1.200076          1.491948              9.859601  \n",
       "1                 1.212367          1.075582              9.844448  \n",
       "2                 1.212550          1.145893              9.810509  \n",
       "3                 1.203370          1.205991              9.806760  \n",
       "4                 1.216755          1.514554              9.829055  \n",
       "...                    ...               ...                   ...  \n",
       "53114             0.728639          1.468925              9.706023  \n",
       "53115             0.687962          1.071500              9.717415  \n",
       "53116             0.708404          1.174106              9.711826  \n",
       "53117             0.734298          0.983234              9.717415  \n",
       "53118             0.740144          0.783797              9.703838  \n",
       "\n",
       "[3930798 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.loader import load_complete_dataset\n",
    "from data.preprocessing import add_module_columns\n",
    "\n",
    "dataset = load_complete_dataset()\n",
    "add_module_columns(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a1e4df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tsfresh in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (0.21.1)\n",
      "Requirement already satisfied: requests>=2.9.1 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.15.1 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (2.3.5)\n",
      "Requirement already satisfied: pandas>=0.25.0 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (2.3.3)\n",
      "Requirement already satisfied: statsmodels>=0.13 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (0.14.5)\n",
      "Requirement already satisfied: patsy>=0.4.1 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (1.0.2)\n",
      "Requirement already satisfied: pywavelets in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (1.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (1.7.2)\n",
      "Requirement already satisfied: tqdm>=4.10.0 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (4.67.1)\n",
      "Requirement already satisfied: stumpy>=1.7.2 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (1.13.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.14.0 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tsfresh) (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from pandas>=0.25.0->tsfresh) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from pandas>=0.25.0->tsfresh) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from pandas>=0.25.0->tsfresh) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from requests>=2.9.1->tsfresh) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from requests>=2.9.1->tsfresh) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from requests>=2.9.1->tsfresh) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from requests>=2.9.1->tsfresh) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from scikit-learn>=0.22.0->tsfresh) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from scikit-learn>=0.22.0->tsfresh) (3.6.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from statsmodels>=0.13->tsfresh) (25.0)\n",
      "Requirement already satisfied: numba>=0.57.1 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from stumpy>=1.7.2->tsfresh) (0.62.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from tqdm>=4.10.0->tsfresh) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from numba>=0.57.1->stumpy>=1.7.2->tsfresh) (0.45.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kille\\onedrive\\desktop\\uc\\tcd\\project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.25.0->tsfresh) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e561d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_gaps(timestamps, gap_threshold):\n",
    "    \"\"\"\n",
    "    Deteta intervalos onde a diferença entre amostras consecutivas excede o threshold.\n",
    "    timestamps: numpy array de floats/ints (ordenado)\n",
    "    gap_threshold: valor máximo permitido entre amostras\n",
    "    Retorna: lista de tuplos (gap_start, gap_end)\n",
    "    \"\"\"\n",
    "    # Calcula a diferença entre amostras consecutivas\n",
    "    diffs = np.diff(timestamps)\n",
    "    \n",
    "    # Encontra índices onde a diferença é maior que o permitido\n",
    "    gap_indices = np.where(diffs > gap_threshold)[0]\n",
    "    \n",
    "    gaps = []\n",
    "    for idx in gap_indices:\n",
    "        # O gap ocorre entre o elemento idx e o elemento idx+1\n",
    "        start_gap = timestamps[idx]\n",
    "        end_gap = timestamps[idx + 1]\n",
    "        gaps.append((start_gap, end_gap))\n",
    "        \n",
    "    return gaps\n",
    "\n",
    "def intersects_gap(win_start, win_end, gap_list):\n",
    "    \"\"\"\n",
    "    Verifica se a janela [win_start, win_end) intersecta algum gap.\n",
    "    \"\"\"\n",
    "    for g_start, g_end in gap_list:\n",
    "        # Lógica de intersecção:\n",
    "        # (StartGap < WinEnd) E (EndGap > WinStart)\n",
    "        if g_start < win_end and g_end > win_start:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def create_sliding_windows(df, window_ms, step_ms, gap_threshold_ms=100):\n",
    "    print(\"A preparar dados e detetar gaps...\")\n",
    "    \n",
    "    # 1. Preparação Básica\n",
    "    # Garantir ordenação (Crucial para searchsorted e diff)\n",
    "    df = df.sort_values(by=[\"participant_id\", \"device_id\", \"timestamp\"]).reset_index(drop=True)\n",
    "    \n",
    "    # Identificar colunas\n",
    "    if 'activity_label' in df.columns: lbl_col = 'activity_label'\n",
    "    elif 'actitivy_label' in df.columns: lbl_col = 'actitivy_label'\n",
    "    else: lbl_col = 'activity'\n",
    "    \n",
    "    # Colunas de sensores para extrair\n",
    "    sensor_cols = [c for c in df.columns if c not in \n",
    "                   ['participant_id', 'device_id', 'timestamp', 'datetime', 'grid_time', lbl_col, 'window_id']]\n",
    "\n",
    "    # Estruturas de dados para o loop\n",
    "    windows_data = []\n",
    "    w_id_global = 0\n",
    "    \n",
    "    # 2. Iterar por Participante (Processamento Independente)\n",
    "    for p_id, df_p in df.groupby(\"participant_id\"):\n",
    "        \n",
    "        # Dicionários para acesso rápido aos dados deste participante\n",
    "        # Chave: device_id -> Valor: (timestamps_array, labels_array, values_matrix)\n",
    "        devices_data = {}\n",
    "        device_gaps = {}\n",
    "        device_bounds = []\n",
    "        \n",
    "        unique_devices = df_p['device_id'].unique()\n",
    "        \n",
    "        # --- PRÉ-PROCESSAMENTO DO PARTICIPANTE ---\n",
    "        valid_participant = True\n",
    "        \n",
    "        for d_id in unique_devices:\n",
    "            # Extrair dados do dispositivo\n",
    "            df_d = df_p[df_p['device_id'] == d_id]\n",
    "            ts = df_d['timestamp'].values\n",
    "            \n",
    "            if len(ts) == 0:\n",
    "                valid_participant = False\n",
    "                break\n",
    "                \n",
    "            # Detetar Gaps\n",
    "            gaps = detect_gaps(ts, gap_threshold_ms)\n",
    "            device_gaps[d_id] = gaps\n",
    "            \n",
    "            # Guardar dados em memória (numpy é mais rápido que pandas no loop)\n",
    "            # Guardamos o DataFrame slice também para facilitar a extração final\n",
    "            devices_data[d_id] = {\n",
    "                'ts': ts,\n",
    "                'lbl': df_d[lbl_col].values,\n",
    "                'df_slice': df_d  # Mantemos o slice do pandas para extrair colunas depois\n",
    "            }\n",
    "            \n",
    "            # Guardar limites (min, max)\n",
    "            device_bounds.append((ts[0], ts[-1]))\n",
    "            \n",
    "        if not valid_participant or not device_bounds:\n",
    "            continue\n",
    "            \n",
    "        # 3. CALCULAR JANELA DE OPERAÇÃO COMUM (Global Bounds)\n",
    "        # O início global é o MAIOR dos inícios (todos têm de ter começado)\n",
    "        start_global = max(b[0] for b in device_bounds)\n",
    "        # O fim global é o MENOR dos fins (todos têm de estar ativos)\n",
    "        end_global = min(b[1] for b in device_bounds)\n",
    "        \n",
    "        # Se a janela útil for menor que o tamanho da janela, ignorar participante\n",
    "        if (end_global - start_global) < window_ms:\n",
    "            continue\n",
    "            \n",
    "        # 4. LOOP DE GERAÇÃO DE JANELAS\n",
    "        curr_time = start_global\n",
    "        \n",
    "        while curr_time + window_ms <= end_global:\n",
    "            win_start = curr_time\n",
    "            win_end = curr_time + window_ms\n",
    "            \n",
    "            window_is_valid = True\n",
    "            temp_window_chunks = [] # Para armazenar os dados se a janela for válida\n",
    "            \n",
    "            # Validar contra TODOS os dispositivos\n",
    "            for d_id in unique_devices:\n",
    "                # A. Checar Gaps\n",
    "                if intersects_gap(win_start, win_end, device_gaps[d_id]):\n",
    "                    window_is_valid = False\n",
    "                    break\n",
    "                \n",
    "                # B. Obter Índices (SearchSorted é O(log N) - Muito Rápido)\n",
    "                ts_arr = devices_data[d_id]['ts']\n",
    "                # Encontrar onde começa e onde acaba a janela neste array\n",
    "                idx_start = np.searchsorted(ts_arr, win_start, side='left')\n",
    "                idx_end = np.searchsorted(ts_arr, win_end, side='left')\n",
    "                \n",
    "                # C. Validar se existem dados suficientes (opcional mas recomendado)\n",
    "                # Se searchsorted devolver o mesmo índice, não há dados no intervalo\n",
    "                if idx_start == idx_end:\n",
    "                    window_is_valid = False\n",
    "                    break\n",
    "                    \n",
    "                # D. Verificar pureza das labels\n",
    "                lbl_arr = devices_data[d_id]['lbl']\n",
    "                labels_in_window = lbl_arr[idx_start:idx_end]\n",
    "                \n",
    "                # np.unique é rápido. Se len > 1, tem labels misturadas.\n",
    "                if len(np.unique(labels_in_window)) > 1:\n",
    "                    window_is_valid = False\n",
    "                    break\n",
    "                \n",
    "                # Se passou tudo, preparar o chunk\n",
    "                # Pegamos o slice do DataFrame original usando iloc relativo\n",
    "                df_slice = devices_data[d_id]['df_slice'].iloc[idx_start:idx_end].copy()\n",
    "                temp_window_chunks.append(df_slice)\n",
    "            \n",
    "            # SE A JANELA FOR VÁLIDA EM TODOS OS DEVICES\n",
    "            if window_is_valid:\n",
    "                # Concatenar todos os chunks desta janela\n",
    "                # (Eles ficam empilhados verticalmente, como tinhas no original)\n",
    "                win_df = pd.concat(temp_window_chunks)\n",
    "                win_df['window_id'] = w_id_global\n",
    "                windows_data.append(win_df)\n",
    "                \n",
    "                w_id_global += 1\n",
    "            \n",
    "            # Avançar no tempo\n",
    "            curr_time += step_ms\n",
    "\n",
    "    print(f\"Processamento concluído. {len(windows_data)} janelas geradas.\")\n",
    "    \n",
    "    if not windows_data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 5. RECONSTRUÇÃO FINAL\n",
    "    final_df = pd.concat(windows_data, ignore_index=True)\n",
    "    \n",
    "    # Recriação das Colunas de Array (Listas) para TSFresh\n",
    "    acc_cols = ['accelerometer_x', 'accelerometer_y', 'accelerometer_z']\n",
    "    gyro_cols = ['gyroscope_x', 'gyroscope_y', 'gyroscope_z']\n",
    "    mag_cols = ['magnetometer_x', 'magnetometer_y', 'magnetometer_z']\n",
    "    \n",
    "    # Verifica quais colunas existem e cria as listas\n",
    "    if all(c in final_df.columns for c in acc_cols):\n",
    "        final_df['acc_array'] = final_df[acc_cols].values.tolist()\n",
    "    if all(c in final_df.columns for c in gyro_cols):\n",
    "        final_df['gyro_array'] = final_df[gyro_cols].values.tolist()\n",
    "    if all(c in final_df.columns for c in mag_cols):\n",
    "        final_df['mag_array'] = final_df[mag_cols].values.tolist()\n",
    "    if all(c in final_df.columns for c in acc_cols + gyro_cols):\n",
    "        final_df['acc_gyro_array'] = final_df[acc_cols + gyro_cols].values.tolist()\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tsfresh\n",
    "from tsfresh.feature_extraction.feature_calculators import set_property\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from tsfresh.utilities.string_manipulation import convert_to_output_format\n",
    "import numpy as np\n",
    "from config.constants import ACC_ARRAY_COLUMN, ACC_GYRO_COLUMN, COLUMNS_ACCELEROMETER, COLUMNS_GYROSCOPE, COLUMNS_MAGNETOMETER,DEVICES, GYRO_ARRAY_COLUMN\n",
    "from tsfresh import extract_features\n",
    "\n",
    "\n",
    "################################Physicial features#######################################\n",
    "# =============================================================================\n",
    "# 1. INTENSIDADE DE MOVIMENTO (MI)\n",
    "# =============================================================================\n",
    "@set_property(\"fctype\", \"combiner\")\n",
    "def mi_intensity(acc_array,param):\n",
    "    arr = np.vstack(acc_array).astype(float)  # transforma em shape (N,3)\n",
    "    magn = np.linalg.norm(arr, axis=1)\n",
    "    avg_intensity = float(np.mean(magn)) if magn.size else 0.0\n",
    "    variance_intensity = float(np.var(magn)) if magn.size else 0.0\n",
    "    return [(\"avg\",avg_intensity),(\"var\",variance_intensity)]\n",
    "\n",
    "# =============================================================================\n",
    "# 2. SMA (Signal Magnitude Area)\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def sma(acc_array):\n",
    "    arr = np.vstack(acc_array).astype(float)\n",
    "    sma_vals = np.sum(np.abs(arr), axis=1)\n",
    "    return float(np.mean(sma_vals)) if sma_vals.size else 0.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. VALORES PRÓPRIOS EVA\n",
    "# =============================================================================\n",
    "@set_property(\"fctype\", \"combiner\")\n",
    "def EVA(acc_array,param):\n",
    "    arr = np.vstack(acc_array).astype(float)\n",
    "    if arr.shape[0] < 2:\n",
    "        return [(\"ver\", 0.0),(\"head\", 0.0)]\n",
    "    cov = np.cov(arr, rowvar=False)\n",
    "    vals = np.linalg.eigvalsh(cov)\n",
    "    vals_sorted = np.sort(vals)\n",
    "    return [(\"ver\", float(vals_sorted[0])), (\"head\", float(vals_sorted[-1]))]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. CAGH – Correlação gravidade (aprox eixo X) × heading (norma YZ)\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def cagh(acc_array):\n",
    "    arr = np.vstack(acc_array).astype(float)\n",
    "    if arr.shape[1] < 3:\n",
    "        return 0.0\n",
    "    ax = arr[:, 0]              # direção da gravidade\n",
    "    heading = np.linalg.norm(arr[:, 1:3], axis=1)\n",
    "    if len(heading) < 2:\n",
    "        return 0.0\n",
    "    # derivada discreta da heading\n",
    "    heading_deriv = np.diff(heading)\n",
    "    ax_trunc = ax[1:]\n",
    "    if np.std(ax_trunc) == 0 or np.std(heading_deriv) == 0:\n",
    "        return 0.0\n",
    "    return float(np.corrcoef(ax_trunc, heading_deriv)[0, 1])\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5. AVH – Velocidade média ao longo da direção de avanço (heading)\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def avh(acc_array):\n",
    "    arr = np.vstack(acc_array).astype(float)\n",
    "    if arr.shape[1] < 3:\n",
    "        return 0.0\n",
    "    heading_acc = np.linalg.norm(arr[:, 1:3], axis=1)\n",
    "    # integração sem dt → acumulado discreto (unidades arbitrárias)\n",
    "    velocity = np.cumsum(heading_acc)\n",
    "\n",
    "    return float(np.mean(np.abs(velocity))) if velocity.size else 0.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 6. AVG – Velocidade média ao longo da direção da gravidade (aprox eixo X)\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def avg(acc_array):\n",
    "    arr = np.vstack(acc_array).astype(float)\n",
    "    ax = arr[:, 0]\n",
    "    velocity = np.cumsum(ax)\n",
    "    return float(np.mean(np.abs(velocity))) if velocity.size else 0.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 7. ARATG – Ângulos médios de rotação (usa gyro_x como rotação no eixo gravidade)\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def aratg(gyro_array):\n",
    "    arr = np.vstack(gyro_array).astype(float)\n",
    "    gx = arr[:, 0]  # rotação em torno da gravidade\n",
    "    angle_increment = np.abs(gx)  # sem dt → soma discreta\n",
    "    return float(np.mean(angle_increment)) if angle_increment.size else 0.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 8. DF – Dominant Frequency (por eixo individual)\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def dominant_frequency_axis(signal_1d):\n",
    "    arr = np.asarray(signal_1d, dtype=float)\n",
    "    if arr.size < 2:\n",
    "        return 0.0\n",
    "    arr = arr - np.mean(arr)\n",
    "    fft_vals = np.fft.rfft(arr)\n",
    "    power = np.abs(fft_vals)**2\n",
    "    power[0] = 0  # excluir DC\n",
    "    idx = np.argmax(power)\n",
    "    return float(idx)  # índice do pico (freq ≈ idx se dt=1)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 9. ENERGY – Energia por eixo\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def energy_axis(signal_1d):\n",
    "    s = np.asarray(signal_1d, dtype=float)\n",
    "    if s.size < 2:\n",
    "        return 0.0\n",
    "    s = s - np.mean(s)\n",
    "    fft_vals = np.fft.rfft(s)\n",
    "    power = np.abs(fft_vals)**2\n",
    "    power[0] = 0\n",
    "    return float(np.sum(power))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 10. AAE – Energia média dos 3 eixos do acelerómetro\n",
    "# =============================================================================\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def aae(acc_array):\n",
    "    arr = np.vstack(acc_array).astype(float)\n",
    "    energy = np.sum(arr**2, axis=1)  # ax² + ay² + az²\n",
    "    return float(np.mean(energy)) if energy.size else 0.0\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 11. ARE – Energia média dos 3 eixos do giroscópio\n",
    "# =============================================================================\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def are(gyro_array):\n",
    "    arr = np.vstack(gyro_array).astype(float)\n",
    "    energy = np.sum(arr**2, axis=1)\n",
    "\n",
    "    return float(np.mean(energy)) if energy.size else 0.0\n",
    "\n",
    "#####################Features estatisticas######################################\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def mean_crossing_rate(x):\n",
    "    \"\"\"\n",
    "    Número de cruzamentos da série com a sua média (Mean Crossing Rate).\n",
    "    \"\"\"\n",
    "    arr = np.asarray(x, dtype=float)\n",
    "    mean_val = np.mean(arr)\n",
    "    # vetor booleano indicando se cada ponto está acima ou abaixo da média\n",
    "    above = arr > mean_val\n",
    "    # cruzamentos acontecem quando o estado muda de True → False ou False → True\n",
    "    crossings = np.sum(above[:-1] != above[1:])\n",
    "    return int(crossings)\n",
    "\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def spectral_entropy(x: pd.Series) -> float:\n",
    "    y = np.array(x, dtype=float) \n",
    "    y = y - y.mean()\n",
    "    psd = np.abs(np.fft.rfft(y)) ** 2\n",
    "    psd_sum = psd.sum()\n",
    "    if psd_sum == 0:\n",
    "        return 0.0\n",
    "    p = psd / psd_sum\n",
    "    p = p[p > 0]\n",
    "    se = -np.sum(p * np.log2(p))\n",
    "    return float(se / np.log2(len(psd)))\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def interq_range(x):\n",
    "    \"\"\"\n",
    "    Amplitude Interquartil (IQR = P75 - P25)\n",
    "    \"\"\"\n",
    "    arr = np.asarray(x, dtype=float)\n",
    "\n",
    "    if arr.size == 0:\n",
    "        return 0.0\n",
    "\n",
    "    q75 = np.percentile(arr, 75)\n",
    "    q25 = np.percentile(arr, 25)\n",
    "    return float(q75 - q25)\n",
    "\n",
    "\n",
    "@set_property(\"fctype\", \"simple\")\n",
    "def averaged_derivative(x: pd.Series,**kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Derivada média absoluta de um sinal 1D.\n",
    "    Usada em reconhecimento de fala e escrita.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(x, dtype=float)\n",
    "\n",
    "    if arr.size < 2:\n",
    "        return 0.0\n",
    "\n",
    "    # primeira derivada: |x[i] - x[i-1]|\n",
    "    derivative = np.abs(np.diff(arr))\n",
    "\n",
    "    return float(np.mean(derivative))\n",
    "\n",
    "\n",
    "\n",
    "@set_property(\"fctype\", \"combiner\")\n",
    "def pairwise_correlation(x, param):\n",
    "    arr = np.array(x.tolist())  # N x 6\n",
    "    acc = arr[:, :3]\n",
    "    gyro = arr[:, 3:]\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    # Acc interno\n",
    "    corr_acc = np.corrcoef(acc, rowvar=False)\n",
    "    features.append(('corr_acc_xy', corr_acc[0,1]))\n",
    "    features.append(('corr_acc_xz', corr_acc[0,2]))\n",
    "    features.append(('corr_acc_yz', corr_acc[1,2]))\n",
    "    \n",
    "    # Gyro interno\n",
    "    corr_gyro = np.corrcoef(gyro, rowvar=False)\n",
    "    features.append(('corr_gyro_xy', corr_gyro[0,1]))\n",
    "    features.append(('corr_gyro_xz', corr_gyro[0,2]))\n",
    "    features.append(('corr_gyro_yz', corr_gyro[1,2]))\n",
    "    \n",
    "    # Acc vs Gyro\n",
    "    axes = [\"x\",\"y\",\"z\"]\n",
    "    for i, a in enumerate(axes):\n",
    "        for j, g in enumerate(axes):\n",
    "            features.append((f'acc_{a}_gyro_{g}', np.corrcoef(acc[:,i], gyro[:,j])[0,1]))    \n",
    "    return [(name, val) for name,val in features]\n",
    "\n",
    "\n",
    "\n",
    "setattr(tsfresh.feature_extraction.feature_calculators, 'mean_crossing_rate', mean_crossing_rate)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators, 'averaged_derivative', averaged_derivative)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators, 'spectral_entropy', spectral_entropy)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"pairwise_correlation\",pairwise_correlation)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"interq_range\",interq_range)\n",
    "\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"mi_intensity\", mi_intensity)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"sma\", sma)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"EVA\", EVA)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"cagh\",cagh)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"avh\",avh)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"aae\",aae)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"avg\",avg)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"aratg\",aratg)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"are\",are)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"dominant_frequency_axis\",dominant_frequency_axis)\n",
    "setattr(tsfresh.feature_extraction.feature_calculators,\"energy_axis\",energy_axis)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_long_format(df, label_col='actitivy_label'):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Criar o ID Único (User_Device_Window)\n",
    "    # Convertemos para int->str para garantir formato limpo \"14_1_0\"\n",
    "    p_str = df['participant_id'].astype(float).astype(int).astype(str)\n",
    "    d_str = df['device_id'].astype(float).astype(int).astype(str)\n",
    "    w_str = df['window_id'].astype(float).astype(int).astype(str)\n",
    "    \n",
    "    df['id'] = p_str + \"_\" + d_str + \"_\" + w_str\n",
    "\n",
    "    # 2. Extrair o Mapeamento de Labels (ID -> Activity)\n",
    "    # Como assumimos que a janela é pura, basta pegar a primeira linha de cada ID\n",
    "    labels_map = df.drop_duplicates(subset=['id']).set_index('id')[label_col]\n",
    "\n",
    "    # 3. Criar Eixo do Tempo (0, 1, 2... N dentro da janela)\n",
    "    df['time'] = df.groupby('id').cumcount()\n",
    "\n",
    "    # 4. Transformar em Long Format (Melt)\n",
    "    vars_to_melt = (\n",
    "        COLUMNS_ACCELEROMETER + \n",
    "        COLUMNS_GYROSCOPE + \n",
    "        COLUMNS_MAGNETOMETER + \n",
    "        [ACC_GYRO_COLUMN, ACC_ARRAY_COLUMN, GYRO_ARRAY_COLUMN]\n",
    "    )\n",
    "    \n",
    "    # Filtra apenas as colunas que realmente existem no df\n",
    "    vars_present = [v for v in vars_to_melt if v in df.columns]\n",
    "\n",
    "    long_df = df.melt(\n",
    "        id_vars=['id', 'time'],\n",
    "        value_vars=vars_present,\n",
    "        var_name='kind',\n",
    "        value_name='value'\n",
    "    )\n",
    "    \n",
    "    # Retorna o DataFrame Longo E o Mapa de Labels\n",
    "    return long_df, labels_map\n",
    "\n",
    "\n",
    "def df_to_tsfresh_format(df):\n",
    "    long_df = pd.DataFrame()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col in [\"window_id\", \"time\", \"device_id\", \"id\",\"participant_id\"]:\n",
    "            continue\n",
    "        \n",
    "        tmp = pd.DataFrame({\n",
    "            \"id\": df[\"id\"],\n",
    "            \"time\": df[\"time\"],\n",
    "            \"kind\": col,  # acc_x, acc_y, etc.\n",
    "            \"value\": df[col]\n",
    "        })\n",
    "        \n",
    "        long_df = pd.concat([long_df, tmp], ignore_index=True)\n",
    "\n",
    "    return long_df\n",
    "\n",
    "\n",
    "def extract_features_sensors(dataframe, window_size, step_size):\n",
    "    # 1) Criar janelas\n",
    "    print(\"starting\")\n",
    "    df_windowed = create_sliding_windows(\n",
    "    df=dataframe, \n",
    "    window_ms=window_size,           # Quero 2 segundos\n",
    "    step_ms=step_size   # 50% de sobreposição\n",
    ")\n",
    "\n",
    "   \n",
    "    df = df_windowed[\n",
    "        COLUMNS_ACCELEROMETER +\n",
    "        COLUMNS_GYROSCOPE +\n",
    "        COLUMNS_MAGNETOMETER +\n",
    "        [\"device_id\",\"window_id\",\"participant_id\",\"actitivy_label\", ACC_GYRO_COLUMN, ACC_ARRAY_COLUMN, GYRO_ARRAY_COLUMN]\n",
    "    ]\n",
    "    long_df,labels = to_long_format(df)\n",
    "    \n",
    "\n",
    "    stat_features = {\n",
    "        \"mean\": None,\n",
    "        \"median\": None,\n",
    "        \"standard_deviation\": None,\n",
    "        \"variance\": None,\n",
    "        \"root_mean_square\": None,\n",
    "        \"skewness\": None,\n",
    "        \"kurtosis\": None,\n",
    "        \"number_crossing_m\": [{\"m\": 0}],   # zero-crossing\n",
    "        \"mean_crossing_rate\": None,\n",
    "        \"averaged_derivative\": None,\n",
    "        \"spectral_entropy\": None,\n",
    "        \"interq_range\": None,\n",
    "    }\n",
    "\n",
    "    # aplicar estatísticas a todos os eixos individuais\n",
    "    kind_to_fc_parameters = {k: stat_features.copy()\n",
    "                             for k in COLUMNS_ACCELEROMETER + COLUMNS_GYROSCOPE}\n",
    "\n",
    "    # features combinadas acc+gyro\n",
    "    kind_to_fc_parameters[ACC_GYRO_COLUMN] = {\n",
    "        \"pairwise_correlation\": None\n",
    "    }\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5. FEATURE SET – FÍSICAS\n",
    "    # ---------------------------------------------------------\n",
    "    physical_features = {\n",
    "        \"dominant_frequency_axis\": None,\n",
    "        \"energy_axis\": None\n",
    "    }\n",
    "\n",
    "    # adicionar físicas aos eixos individuais\n",
    "    for k in COLUMNS_ACCELEROMETER + COLUMNS_GYROSCOPE:\n",
    "        kind_to_fc_parameters[k].update(physical_features)\n",
    "\n",
    "    # 5.1 — features específicas para acc_array (3D)\n",
    "    kind_to_fc_parameters[ACC_ARRAY_COLUMN] = {\n",
    "        \"mi_intensity\": None,\n",
    "        \"sma\": None,\n",
    "        \"EVA\": None,\n",
    "        \"cagh\": None,\n",
    "        \"avh\": None,\n",
    "        \"aae\": None,\n",
    "    }\n",
    "\n",
    "    # 5.2 — gyroscope_x recebe AVG\n",
    "    if \"gyroscope_x\" in kind_to_fc_parameters:\n",
    "        kind_to_fc_parameters[\"gyroscope_x\"].update({\"avg\": None})\n",
    "\n",
    "    # 5.3 — gyro_array recebe ARE e ARATG\n",
    "    kind_to_fc_parameters[GYRO_ARRAY_COLUMN] = {\n",
    "        \"aratg\": None,\n",
    "        \"are\": None\n",
    "    }\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 6. EXTRAÇÃO FINAL DE FEATURES\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Extracting features...\")\n",
    "    features = extract_features(\n",
    "        long_df,\n",
    "        column_id=\"id\",\n",
    "        column_sort=\"time\",\n",
    "        column_kind=\"kind\",\n",
    "        column_value=\"value\",\n",
    "        kind_to_fc_parameters=kind_to_fc_parameters,\n",
    "        n_jobs=0\n",
    "    )\n",
    "    features['activity'] = labels\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70aa3a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "A preparar dados e detetar gaps...\n",
      "Processamento concluído. 12337 janelas geradas.\n",
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 740220/740220 [24:29<00:00, 503.85it/s] \n"
     ]
    }
   ],
   "source": [
    "features = extract_features_sensors(dataset,2000, 1000) ## 2 segundos de janela, 1 segundo de overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ea2503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clean_database(features):\n",
    "    df_final = features.copy()\n",
    "\n",
    "\n",
    "    if 'Unnamed: 0' in df_final.columns:\n",
    "        id_source = df_final['Unnamed: 0'].astype(str)\n",
    "        df_final.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    else:\n",
    "        id_source = df_final.index.to_series().astype(str)\n",
    "\n",
    "    ids_split = id_source.str.split('_', expand=True)\n",
    "\n",
    "\n",
    "    df_final.insert(0, 'participant_id', pd.to_numeric(ids_split[0]).astype(int))\n",
    "    \n",
    "\n",
    "    df_final.insert(1, 'device_id', pd.to_numeric(ids_split[1]).astype(int))\n",
    "    \n",
    "    # Window (Coluna 2 do split)\n",
    "    df_final.insert(2, 'window_id', pd.to_numeric(ids_split[2]).astype(int))\n",
    "    \n",
    "\n",
    "    df_final = df_final.reset_index(drop=True)\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "df_clean = create_clean_database(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98134a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Final Obtido: (12337, 553)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def reshape_features_robust(df_clean):\n",
    "    df_clean = df_clean.copy()\n",
    "    \n",
    "    # 1. TRATAMENTO DE TIPOS E SORTING\n",
    "    try:\n",
    "        df_clean['participant_id'] = df_clean['participant_id'].astype(float).astype(int)\n",
    "        df_clean['device_id'] = df_clean['device_id'].astype(float).astype(int)\n",
    "        df_clean['window_id'] = df_clean['window_id'].astype(float).astype(int)\n",
    "    except Exception as e:\n",
    "        print(f\"Aviso tipos: {e}\")\n",
    "\n",
    "    df_clean = df_clean.sort_values(by=['participant_id', 'device_id', 'window_id'])\n",
    "\n",
    "    # 2. DETETAR COLUNA DE LABEL\n",
    "    # Verifica qual o nome correto da coluna\n",
    "    if 'activity_label' in df_clean.columns: \n",
    "        lbl_col = 'activity_label'\n",
    "    elif 'activity' in df_clean.columns: \n",
    "        lbl_col = 'activity'\n",
    "    elif 'actitivy_label' in df_clean.columns: # Caso haja typo antigo\n",
    "        lbl_col = 'actitivy_label'\n",
    "    else:\n",
    "        print(\"ERRO: Coluna de atividade não encontrada!\")\n",
    "        return None\n",
    "\n",
    "    # 3. CRIAR ID ALINHADO\n",
    "    # Nota: Isto só funciona bem porque garantimos antes que todos os devices têm o mesmo nº de janelas\n",
    "    df_clean['aligned_window_id'] = df_clean.groupby(['participant_id', 'device_id']).cumcount()\n",
    "\n",
    "    # Agrupamos por Participante e Janela e pegamos na primeira label que encontrarmos\n",
    "    # (Como a janela é pura, a label é igual para o device 1, 2, 3...)\n",
    "    y_labels = df_clean.groupby(['participant_id', 'aligned_window_id'])[lbl_col].first()\n",
    "    \n",
    "    # 4. PREPARAR PIVOT (Apenas features numéricas)\n",
    "    cols_to_ignore = ['participant_id', 'window_id', 'device_id', lbl_col, 'id', 'Unnamed: 0', 'aligned_window_id']\n",
    "    feature_cols = [c for c in df_clean.columns if c not in cols_to_ignore]\n",
    "    \n",
    "    # 5. PIVOT\n",
    "    df_wide = df_clean.pivot(\n",
    "        index=['participant_id', 'aligned_window_id'], \n",
    "        columns='device_id', \n",
    "        values=feature_cols\n",
    "    )\n",
    "    \n",
    "    # 6. ACHATAR NOMES DAS COLUNAS (Flatten)\n",
    "    # Transforma (mean_x, 1) em \"S1_mean_x\"\n",
    "    df_wide.columns = [f\"S{int(dev)}_{feat}\" for feat, dev in df_wide.columns]\n",
    "    \n",
    "    # --- O FIX: JUNTAR AS LABELS DE VOLTA ---\n",
    "    # O join funciona automaticamente porque o index (participant, aligned_window) é igual nos dois\n",
    "    df_wide = df_wide.join(y_labels)\n",
    "    \n",
    "    # 7. FINALIZAÇÃO\n",
    "    df_wide = df_wide.reset_index()\n",
    "    df_wide.rename(columns={'aligned_window_id': 'window_id'}, inplace=True)\n",
    "    \n",
    "    return df_wide\n",
    "\n",
    "# Testar\n",
    "X_final_550 = reshape_features_robust(df_clean)\n",
    "print(f\"Shape Final Obtido: {X_final_550.shape}\")\n",
    "if 'activity_label' in X_final_550.columns:\n",
    "    print(X_final_550[['participant_id', 'window_id', 'activity_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c5db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_550.to_csv('X_final_550.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
